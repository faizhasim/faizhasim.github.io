
<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Reveal.js</title>
        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/black.css" id="theme">
        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- If the query includes 'print-pdf', use the PDF print sheet -->
        <script>
          document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
        </script>
    </head>
    <body>

        <div class="reveal">
            <div class="slides"><section ><section data-markdown><script type="text/template">
![img/ld-200.png](img/ld-200.png)

Moving Learndot.com from 🐈 Computing to 🐄 Computing
</script></section><section data-markdown><script type="text/template">
![img/rocket-left-white-text.png](img/rocket-left-white-text.png)

- Mohd Faiz Hasim
- Developer with Architect role in ServiceRocket engineering
- Responsible for Learndot
</script></section></section><section ><section data-markdown><script type="text/template">
![img/ld-300.png](img/ld-300.png)

## What is Learndot?
</script></section><section data-markdown><script type="text/template">
![img/ld_com_1.gif](img/ld_com_1.gif)
</script></section><section data-markdown><script type="text/template">
- LMS for business
- Designed for low barrier of entry to LMS
- API-first design
- Multi devices
</script></section><section data-markdown><script type="text/template">
![img/learner.gif](img/learner.gif)
</script></section><section data-markdown><script type="text/template">
![img/admin-exp.gif](img/admin-exp.gif)
</script></section></section><section ><section data-markdown><script type="text/template">
## Pet Computing

![img/cat1.gif](img/cat1.gif) ![img/cat2.gif](img/cat2.gif) ![img/cat3.gif](img/cat3.gif)
</script></section><section data-markdown><script type="text/template">
### Pet Definition from Dictionary

![img/define_pet.jpg](img/define_pet.jpg)
</script></section><section data-markdown><script type="text/template">
## Cattle Computing

![img/cow1.gif](img/cow1.gif) ![img/cow2.gif](img/cow2.gif) ![img/cow3.gif](img/cow3.gif)
</script></section><section data-markdown><script type="text/template">
### Pet Definition from Dictionary

![img/define_cattle.jpg](img/define_cattle.jpg)
</script></section><section data-markdown><script type="text/template">
> What happen if you treat a cluster of computing resources like herding a herd of cats and kittens?

[![Herding Cats](http://img.youtube.com/vi/m_MaJDK3VNE/0.jpg)](http://www.youtube.com/watch?v=m_MaJDK3VNE "EDS, an HP Company 'Cat Herders'")
</script></section></section><section ><section data-markdown><script type="text/template">
## Kitten-computing era (Part 1)

🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈

- We have names for each servers.
- Servers are enterprise-grade and expensive.
- Taking care of the servers take huge time and commitment.
- Downtimes from third party hosting company.
</script></section><section data-markdown><script type="text/template">
## Kitten-computing era (Part 2)

🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈🐈

- Spinning up new VM take days.
- Require lots of in-house solutions.
- We are not experts in DBA. (But, our database never had any issues! Lucky?).
- We want velocity in longer run in delivering values to customer.
- We want strong, battle-tested infra for microservices later.
</script></section><section data-markdown><script type="text/template">
## Cattle-computing era (Part 1)

🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄

- Smaller compute units using autoscaling group. Thus, "self-healing" service.
- Highly available services (load balancers and internal services included).
- Centralised logging. (Actively in progress).
</script></section><section data-markdown><script type="text/template">
## Cattle-computing era (Part 2)

🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄

- Auditable infrastructure.
- Most services are long running process.
- But more software designs relies on ephemeral computing mindset.
- Pretty much locked into AWS for now.
</script></section></section><section ><section data-markdown><script type="text/template">
## Inspired by `Functional Programming`

Eg: Amount of characters for a unique word.

> Example in Scala

</script></section><section data-markdown><script type="text/template">
Iterative approach

```scala
val input = Seq(
  "geek", "camp", "geek", "my", "camp",
  "geek", "camp", "camp", "my", "geek"
)
val outputMutable = scala.collection.mutable.Map[String,Int]()
for (x <- input) {
  outputMutable.contains(x) match {
    case true => outputMutable(x) = outputMutable(x) + 1
    case false => outputMutable(x) = 1
  }
}
val output = outputMutable.toMap
// Map(camp -> 4, my -> 2, geek -> 4)
```
</script></section><section data-markdown><script type="text/template">
Functional approach

```scala
val input = Seq(
  "geek", "camp", "geek", "my", "camp",
  "geek", "camp", "camp", "my", "geek"
)

def sameValue[T](value: T) = value

def valueLength[T](tuple: Tuple2[T, Seq[T]]) = (
  tuple._1,
  tuple._2.length
)

input.groupBy(sameValue).map(valueLength)
// Map(camp -> 4, my -> 2, geek -> 4)
```

In fact, works for other cases:

```scala
object Pet{}
object Cattle{}
List(Pet, Cattle, 4, Cattle, "yet a string", 4)
  .groupBy(sameValue).map(valueLength)
// Map(
//   yet a string -> 1, 4 -> 2,
//   Cattle$@79b63325 -> 2, Pet$@1716c037 -> 1
// )
```
</script></section><section data-markdown><script type="text/template">
### Lessons

- No side effects ➡ Easier mental model.
- Pure function ➡ Small function, only do very specific thing. Single reponsibility rule.
- Decomposition ➡ To make sense of a solution.
- Recomposition ➡ To form a solution from decomposed functions.
</script></section><section data-markdown><script type="text/template">
### How does it influence infrastructure design?

- Decomposed Chef recipes into containers (APIs, UIs, Load Balancers, stores, logs)
- Recomposition happens with docker-compose on single machine deployment.
- On AWS, combination of Elastic Load Balancers and HAProxy in a highly available setup.
- Aligned with microservices idea.
</script></section></section><section ><section data-markdown><script type="text/template">
## Infrastructure as Code

### History

- `Old days - Late 2014`
  - Chef-provisioned Learndot on single VM.
- `Late 2014 - Early 2016`
  - Containerized services, but still in single VM. `docker-compose` was used with minor `Puppet` script.
- `2016 - now`
  - Container as a Service (CaaS) approach on AWS.
</script></section><section data-markdown><script type="text/template">
### Terraform by HashiCorp

![img/terraform-480.png](img/terraform-480.png)

Terraform - Managing AWS Resources
</script></section><section data-markdown><script type="text/template">
#### Why Terraform?

- CloudFormation is effectively one big JSON.
- Smart dependency management that fails as early as planning phase.
- State management using Atlas, but by default visible to us.
- Really nice DSL using HashiCorp Configuration Language (HCL).

Caveats

- In active development, but rapid release and support from HashiCorp.
- Some configurations not supported by Terraform. For eg, we call CloudFormation script from Terraform to
  provision S3 buckets with advanced poliy.
</script></section><section data-markdown><script type="text/template">
```hcl
resource "digitalocean_droplet" "web" {
    name = "tf-web"
    size = "512mb"
    image = "centos-5-8-x32"
    region = "sfo1"
}

resource "dnsimple_record" "hello" {
    domain = "example.com"
    name = "test"
    value = "${digitalocean_droplet.web.ipv4_address}"
    type = "A"
}
```
</script></section><section data-markdown><script type="text/template">
```hcl
provider "aws" {
    access_key = "${var.access_key}"
    secret_key = "${var.secret_key}"
    region = "${var.region}"
}

resource "aws_s3_bucket" "bucket" {
  bucket = "${var.s3_bucket_name}"
  acl = "public-read"

  website {
    index_document = "index.html"
    error_document = "error.html"
  }
```
</script></section><section data-markdown><script type="text/template">
With Atlas

![https://cloud.githubusercontent.com/assets/898384/11377940/955ebf86-9323-11e5-9f30-3bde8fc25098.png](https://cloud.githubusercontent.com/assets/898384/11377940/955ebf86-9323-11e5-9f30-3bde8fc25098.png)
</script></section></section><section ><section data-markdown><script type="text/template">
### Be honest, Embrace failures

![img/nothing-wrong-failure.gif](img/nothing-wrong-failure.gif)
</script></section><section data-markdown><script type="text/template">
Question...

> Any node in cluster might fail, what would you do?
</script></section><section data-markdown><script type="text/template">
Questions...

> One data centre might have network issue, what would you do?
</script></section><section data-markdown><script type="text/template">
And more questions...

> Database out of service so you can't write anything, what would you do?
</script></section><section data-markdown><script type="text/template">
### How we mitigate those potential failures?

- Multiple databases with write and read replicas. Promote read replica to write replica on failure.
- Autoscaling group for provisioning desired amount of EC2 instances.
- EC2 Container Service (ECS) to manage and scheduler task as Docker containers.
- EC2 instances spawned across all availability zones.
</script></section></section><section ><section data-markdown><script type="text/template">
## Monitoring

- DataDog for infrastructure monitoring.
- Some other metrics consolidated into DataDog.
- Eventstream is quite powerful to know how does one event affect another event.
- We use CloudWatch logs for logging. Some part uses ELK.
- DogStatsD - Evolved from StatsD.
</script></section><section data-markdown><script type="text/template">
![img/datadog-hostmap.gif](img/datadog-eventstream.gif)
</script></section><section data-markdown><script type="text/template">
![img/datadog-hostmap.gif](img/datadog-haproxy.gif)
</script></section><section data-markdown><script type="text/template">
![img/datadog-hostmap.gif](img/datadog-hostmap.gif)
</script></section></section><section ><section data-markdown><script type="text/template">
## How's our Cloud Computing stack looks like?


### Philosophy

- Get value out first, optimize progressively.
- Means, ship MVP first, build more knowledge and optimize cost later.
- Leverage AWS services as much as we can.
- Must make developer happy. ie: Efficient deployment pipeline.
</script></section><section data-markdown><script type="text/template">
### Deployment Pipeline

- Developer build task in Jenkins.
- Jenkins will update Terraform variables into Atlas.
- Atlas update Docker tag of the affected services.
- ECS will start scheduling new containers to replace old containers by performing rolling updates. No downtime.
</script></section><section data-markdown><script type="text/template">
![img/cd-pipeline.gif](img/cd-pipeline.gif)
</script></section><section data-markdown><script type="text/template">
### Internet-facing load balancers

- Some config and SSL keys are automatically configured and HAProxy will be hot-reloaded.
- Wrote companion script in NodeJS.
- Master-master setup HAProxy with hot reloading capability, distributed acorss multiple AZ.
- HAProxy health check done via Route 53 health check.
- We don't use ELB as Internet-facing load balancer due to some limitations of ELB.
- HAProxy in containers, provisioned and scheduled by ECS.
- HAProxy is doing level 7 load balancing.
</script></section><section data-markdown><script type="text/template">
### Internal Services using CaaS approach

- ECS: Easy to get started. High coupling with other AWS services. Low barrier of entry. Suitable for our use case with small team.
- Long running services provisioned as `ECS service`, managed by ECS.
- Means, ECS will keep desired amount of running containers.
- Ephemeral task executed via ECS too. For eg: migration task.
- EC2 instances provisioned via autoscaling group.
- All running on top of lean CoreOS.
- Service discovery happens via ELB itself. Good enough for current use case.
- Might look into point-to-point discovery using Consul, in the future.
</script></section><section data-markdown><script type="text/template">
### Additional notes

- Application server are immutable.
- Storage: S3 buckets, CDN, RDS.
- Security: Do not allow anything other than HTTP(S) ports.
</script></section></section><section ><section data-markdown><script type="text/template">
## Recap: What we have now
</script></section><section data-markdown><script type="text/template">
> Immutable infrastructure.

- Shipped containers can be swap by ECS just by updating Terraform.
</script></section><section data-markdown><script type="text/template">
> One-click deployment from code commit to production/staging

- Or no-click deployment on staging.
</script></section><section data-markdown><script type="text/template">
> Fast release cycle.

- Can release multiple times a day.
</script></section><section data-markdown><script type="text/template">
> Embracing failures.

- Eg: Containers did die on production.
- New one spun up on health check failure.
</script></section><section data-markdown><script type="text/template">
![img/ecs-container-down.gif](img/ecs-container-down.gif)
</script></section><section data-markdown><script type="text/template">
> Monitoring and logs

- Containers did die because insufficient heap.
- We are alerted and we can tweak the ECS task definition.
</script></section></section><section  data-markdown><script type="text/template">
#### Going forward

- Ephemeral computing: AWS Lambda and task in ECS cluster.
- Operation optimization. Keep experimenting.
- Cost optimization using spot instances.
</script></section><section  data-markdown><script type="text/template">
> Thank you...

</script></section></div>
        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>
            function extend() {
              var target = {};
              for (var i = 0; i < arguments.length; i++) {
                var source = arguments[i];
                for (var key in source) {
                  if (source.hasOwnProperty(key)) {
                    target[key] = source[key];
                  }
                }
              }
              return target;
            }

            // Optional libraries used to extend on reveal.js
            var deps = [
              { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
              { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
              { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
              { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
              { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
              { src: 'plugin/math/math.js', async: true }
            ];

            // default options to init reveal.js
            var defaultOptions = {
              controls: true,
              progress: true,
              history: true,
              center: true,
              transition: 'default',
              dependencies: deps
            };

            // options from URL query string
            var queryOptions = Reveal.getQueryHash() || {};

            var options = {
  "controls": true,
  "progress": true,
  "history": true,
  "slideNumber": false,
  "transition": "slide",
  "transitionSpeed": "fast",
  "parallaxBackgroundImage": "./img/DSC03290.jpg",
  "parallaxBackgroundSize": "2048px 1278px",
  "mouseWheel": true
};
            options = extend(defaultOptions, options, queryOptions);
            Reveal.initialize(options);
        </script>
    </body>
</html>

